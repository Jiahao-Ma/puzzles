<!DOCTYPE html>
<html>

<head>


  <meta charset="utf-8">
  <meta name="description" content="">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Puzzles</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script type="module" src="static/js/model-viewer.min.js"></script>

  <link href="./static/css/sans.css" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/selection-panel.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="./static/js/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h1 class="title is-1 publication-title">Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction</h1> -->
            <h1 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0">Puzzles: Unbounded Video-Depth Augmentation for</h1>
            <h1 class="title is-2 publication-title" style="margin-top: 0">Scalable End-to-End 3D Reconstruction</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://jiahao-ma.github.io/">Jiahao Ma</a><sup>1,3</sup>,</span>
              <span class="author-block"><a href="https://leiwangr.github.io/">Lei Wang</a><sup>2,3</sup>,</span>
              <span class="author-block"><a href="http://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://people.csiro.au/a/d/david-ahmedtaristizabal">David Ahmedt-Aristizabal</a><sup>3</sup>,</span>
              <span class="author-block"><a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a><sup>3</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Australian National University,</span>
              <span class="author-block"><sup>2</sup>Griffith University,</span>
              <span class="author-block"><sup>3</sup>CSIRO's Data61</span>
            </div>

            <!-- <div class="is-size-5 publication-authors" style="margin-top: 0.5em;">
              <b>Arxiv</b>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">

                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/Jiahao-Ma/puzzles-code" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay controls muted loop playsinline height="100%">
          <source src="materials\video\Puzzles.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <strong>Puzzles</strong>  augments 3D reconstruction training by generating diverse novel viewpoints and 
        realistic camera trajectories from single images or video clips, eliminating redundant frames.
        </h2>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
                <!-- <img src="materials\image\puzzles_cover.jpg" class="center"> -->
                <p>
                    Multi-view 3D reconstruction remains a core challenge in computer vision. Recent methods, 
                    such as DUSt3R and its successors, directly regress pointmaps from image pairs without relying on known scene geometry or camera parameters. 
                    However, the performance of these models is constrained by the diversity and scale of available training data. 
                    In this work, we introduce <strong>Puzzles</strong>, a data augmentation strategy that synthesizes an unbounded volume of high-quality, 
                    posed video-depth data from just a single image or video clip. By simulating diverse camera trajectories and realistic scene geometry through targeted image transformations, 
                    <strong>Puzzles</strong> significantly enhances data variety. Extensive experiments show that integrating <strong>Puzzles</strong> into existing video-based 3D reconstruction pipelines consistently boosts performance, 
                    all without modifying the underlying network architecture. Notably, models trained on only 10% of the original data, augmented with <strong>Puzzles</strong>, still achieve accuracy comparable to those trained on the full dataset.
                </p>
            </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>
        
        
        <img src="materials\image\img2clips.jpg" class="center">
        <div class="content has-text-justified">
            <p style="margin-top: 20px">
                <strong>Image-to-Clips.</strong> (A) Starting from a single RGB-D image, we (B) partition it into ordered, overlapping patches, (C) simulate diverse viewpoints by calibrating virtual camera poses, and (D) generate augmented, posed images with aligned depth maps for use in 3D reconstruction.
            </p>
        </div>
    
        <img src="materials\image\clips2clips.jpg" class="center">
        <div class="content has-text-justified">
            <p style="margin-top: 20px">
                <strong>Clips-to-Clips.</strong> (A) We begin by uniformly sampling frames from a video. (B) A pair-wise overlap matrix is computed to measure frame redundancy, with overlap visualized in purple and overlap ratios annotated in red. (C) Low-redundancy keyframes are then selected, and diverse sub-clips are synthesized from them using the Image-to-Clips method. 
            </p>
        </div>

      </div>
    </div>
  </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -30px">Example</h2>
        
        <img src="materials\image\image2clips_example.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <strong>Example of Image-to-Clips.</strong>  From one image (<em>left</em>), the method samples overlapping patches and assigns 6-DoF camera paths to craft view-consistent clips (<em>right</em>), turning a single frame into diverse, realistic training sequences across human, indoor, and outdoor scenes.
          </p>
        </div>
    
        <img src="materials\image\clips2clips_examples_half.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <strong>Example of Clips-to-Clips.</strong> <em>Top</em>: Consecutive frames from the original training clip.
            <em>Middle</em>:  Selected Keyframes with corresponding patch selections.
            <em>Bottom</em>: Synthetic video clips generated from keyframes using the Image-to-Clips method.
          </p>
        </div>

      </div>
    </div>
  </div>
  </section>




  <section class="hero is-light">
    <div class="hero-body" style="padding: 0;">
      <div class="container is-max-desktop">
        <h3 class="title is-3" style="margin-top: 20px;">Demo</h3>
        <p> Demonstrates how the Image-to-Clips method samples overlapping patches (colored regions) from a single image <br>
           and generates diverse video clips, producing diverse training sequences.</p>
        <div id="carouselVideoReconstruction" class="carousel" data-slides-to-scroll="1" data-slides-to-show="1">
          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\rabbit6.mp4" type="video/mp4">
            </video>
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\studio_room8.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\lamp6.mp4" type="video/mp4">
            </video>
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\wall8.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\boys6.mp4" type="video/mp4">
            </video>

            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\alien8.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\mountain10.mp4" type="video/mp4">
            </video>
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\living_room10.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light">
    <div class="hero-body" style="padding: 0;">
      <div class="container is-max-desktop">
        <h3 class="title is-3" style="margin-top: 50px;">Qualtitative Evaluation</h3>
        <p>
           Side-by-side comparison on real-world captured video: standard 3D reconstruction (left) vs. Puzzles-augmented result (right), <br>
  showcasing richer structural detail and more complete geometry. Click the <strong>arrow</strong> button for extra comparison.
        </p>
        
        <div id="carouselVideoReconstruction" class="carousel" data-slides-to-scroll="1" data-slides-to-show="1">
          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\3.mp4" type="video/mp4">
            </video>
    
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\4.mp4" type="video/mp4">
            </video>
          </div>
            
          <div class="item">
              <video poster="" autoplay controls muted loop playsinline height="100%">
                <source src="materials\video\2.mp4" type="video/mp4">
              </video>

              <video poster="" autoplay controls muted loop playsinline height="100%">
                <source src="materials\video\6.mp4" type="video/mp4">
              </video>
          </div>
          

          <div class="item">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\5.mp4" type="video/mp4">
            </video>

            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="materials\video\1.mp4" type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
  </section>

  <!--/Video Comparison. -->

  <!-- Quantitative Results -->
<section class="section">
  <div class="container is-max-desktop">
    <h3 class="title is-3">Quantitative Evaluation</h3>
    <div class="table-container">
    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth metrics">
      <caption class="has-text-centered">
        <strong>Table&nbsp;1.</strong>
        Quantitative comparison on 7Scenes, NRGBD and DTU.
        Value &amp; relative improvement (Δ) after using <strong>Puzzles</strong>.
      </caption>
      <!-- <p>
        We adopt three representative video-based 3R-series methods, <a href="https://github.com/HengyiWang/spann3r?tab=readme-ov-file">Spann3R</a>, <a href="https://github.com/PKU-VCL-3DV/SLAM3R/tree/main">SLAM3R</a>, and <a href="https://github.com/facebookresearch/fast3r">Fast3R</a>, as baselines.
  Since each was originally trained on a distinct dataset, we preserve their published training protocols and architectures, and retrain them on a unified dataset both \textit{with} and \textit{without} our Puzzles data augmentation. As a result, the reported metrics may deviate from those reported in the original papers; our objective is not to replicate prior results, but to investigate how each model responds to changes in data distribution.
      </p> -->
        <thead>
          <tr>
            <th rowspan="3">Method</th>
            <th rowspan="3">w/ Puzzles</th>
            <th rowspan="3">Data</th>
            <th colspan="4">7Scenes</th>
            <th colspan="4">NRGBD</th>
            <th colspan="4">DTU</th>
          </tr>
          <tr>
            <th colspan="2">Acc&nbsp;↓</th><th colspan="2">Comp&nbsp;↓</th>
            <th colspan="2">Acc&nbsp;↓</th><th colspan="2">Comp&nbsp;↓</th>
            <th colspan="2">Acc&nbsp;↓</th><th colspan="2">Comp&nbsp;↓</th>
          </tr>
          <tr>
            <th>Value</th><th>Δ (%)</th><th>Value</th><th>Δ (%)</th>
            <th>Value</th><th>Δ (%)</th><th>Value</th><th>Δ (%)</th>
            <th>Value</th><th>Δ (%)</th><th>Value</th><th>Δ (%)</th>
          </tr>
        </thead>

        <tbody>
          <!-- Spann3R -->
          <tr>
            <td rowspan="3"><strong>Spann3R</strong></td>
            <td>-</td><td>full</td>
            <td>0.0388</td><td></td><td>0.0253</td><td></td>
            <td>0.0686</td><td></td><td>0.0315</td><td></td>
            <td>6.2432</td><td></td><td>3.1259</td><td></td>
          </tr>
          <tr>
            <td>✓</td><td>1/10</td>
            <td>0.0389</td><td class="bad">-0.26</td><td>0.0248</td><td class="good">+1.98</td>
            <td>0.0753</td><td class="bad">-9.79</td><td>0.0341</td><td class="bad">-8.50</td>
            <td>4.9832</td><td class="good">+20.18</td><td>2.5172</td><td class="good">+19.47</td>
          </tr>
          <tr>
            <td>✓</td><td>full</td>
            <td>0.0330</td><td class="good">+14.94</td><td>0.0224</td><td class="good">+11.46</td>
            <td>0.0644</td><td class="good">+6.00</td><td>0.0291</td><td class="good">+7.51</td>
            <td>5.0004</td><td class="good">+19.90</td><td>2.5113</td><td class="good">+19.66</td>
          </tr>

          <!-- Fast3R -->
          <tr>
            <td rowspan="3"><strong>Fast3R</strong></td>
            <td>-</td><td>full</td>
            <td>0.0412</td><td></td><td>0.0275</td><td></td>
            <td>0.0735</td><td></td><td>0.0287</td><td></td>
            <td>4.2961</td><td></td><td>2.0681</td><td></td>
          </tr>
          <tr>
            <td>✓</td><td>1/10</td>
            <td>0.0402</td><td class="good">+2.30</td><td>0.0272</td><td class="good">+1.09</td>
            <td>0.0772</td><td class="bad">-5.11</td><td>0.0295</td><td class="bad">-2.78</td>
            <td>3.7174</td><td class="good">+13.47</td><td>1.8941</td><td class="good">+8.41</td>
          </tr>
          <tr>
            <td>✓</td><td>full</td>
            <td>0.0342</td><td class="good">+16.99</td><td>0.0239</td><td class="good">+13.09</td>
            <td>0.0684</td><td class="good">+6.94</td><td>0.0259</td><td class="good">+9.75</td>
            <td>3.5912</td><td class="good">+16.41</td><td>1.7379</td><td class="good">+15.96</td>
          </tr>

          <!-- SLAM3R -->
          <tr>
            <td rowspan="3"><strong>SLAM3R</strong></td>
            <td>-</td><td>full</td>
            <td>0.0291</td><td></td><td>0.0245</td><td></td>
            <td>0.0481</td><td></td><td>0.0292</td><td></td>
            <td>4.3820</td><td></td><td>2.4754</td><td></td>
          </tr>
          <tr>
            <td>✓</td><td>1/10</td>
            <td>0.0289</td><td class="good">+0.68</td><td>0.0237</td><td class="good">+3.26</td>
            <td>0.0493</td><td class="bad">-2.49</td><td>0.0313</td><td class="bad">-7.19</td>
            <td>3.5980</td><td class="good">+17.89</td><td>2.0891</td><td class="good">+15.60</td>
          </tr>
          <tr>
            <td>✓</td><td>full</td>
            <td>0.0264</td><td class="good">+9.27</td><td>0.0218</td><td class="good">+11.02</td>
            <td>0.0439</td><td class="good">+8.73</td><td>0.0263</td><td class="good">+9.93</td>
            <td>3.6497</td><td class="good">+16.71</td><td>2.0762</td><td class="good">+16.12</td>
          </tr>

        </tbody>
      </table>
      </div>
      <p>
      To evaluate the impact of Puzzles augmentation, we retrain three video-based 3R-series baselines—<a href="https://github.com/HengyiWang/spann3r?tab=readme-ov-file">Spann3R</a>, <a href="https://github.com/PKU-VCL-3DV/SLAM3R/tree/main">SLAM3R</a>, and <a href="https://github.com/facebookresearch/fast3r">Fast3R</a>—on unified dataset (which differs from their original training data), using each model's published architecture and training protocol, both with and without Puzzles. Reported metrics may therefore diverge from the papers; our goal is to measure how each model reacts to a new data distribution and augmentation.
      </p>
  </div>
</section>

  

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming soon...</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content" style="text-align: center;">
            <p>
              The page template is borrowed from  <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  <script src="static/js/model-viewer.js"></script>
  <script src="static/js/gallery.js"></script>
  <script src="static/js/selection-panel.js"></script>

  <script src="static/js/comparison.js"></script>

  <script src="static/js/video_comparison.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>

</body>

</html>
